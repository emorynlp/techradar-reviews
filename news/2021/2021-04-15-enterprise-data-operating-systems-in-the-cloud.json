{
  "source": "https://www.techradar.com/news/enterprise-data-operating-systems-in-the-cloud",
  "title": "Enterprise data operating systems in the Cloud",
  "category": "computing",
  "updated": "2021-04-15T10:54:48Z",
  "author": "martin-willcox",
  "summary": "What changes in the Cloud? Everything!",
  "article": [
    "The Cloud used to mean \u201crenting someone else\u2019s server\u201d \u2013 but increasingly it is coming to represent a set of architecture and design patterns that define how we design and deliver 21st century Enterprise computing solutions. For data and analytic platform solutions, that means re-thinking solutions in terms of Services, APIs and Data Products.",
    "What changes in the Cloud? Everything! Compute, cloud storage and network services are configured as code and available on-demand. Services can be started, stopped and scaled-up-and-out as required. Operations are automated by default. PAYG pricing models limit risk and enable rapid experimentation, lowering barriers to entry and improving time-to-value. Perhaps most importantly, a rich ecosystem of composable services with well-defined interfaces (\u201cAPIs\u201d) enable \u201csnap together\u201d system development, by enabling Services to be called and connected to create re-useable processes that encapsulate important business processes. At a time of huge economic uncertainty, increasingly what matter are time-to-value and agility; Cloud architectures combined with \u201cDataOps\u201d methods enable agile, incremental development of the data and analytic products without which any digital transformation project is doomed to irrelevance at best, outright failure at worst.",
    "Conceptually, you could argue that much of this isn\u2019t new. The Service Oriented Architecture movement from the noughties, the Object-Oriented programming revolution that preceded it - and even the structured programming movement that dates back to the 50s and 60s \u2013 they all shared many of the same objectives. But as a British Prime Minister once famously observed \u201cwhat matters is what works.\" Cloud design patterns have been shown not just to work well for very many use-cases, but also to scale rapidly and economically. And that\u2019s why they matter.",
    "Durable and flexible Cloud Object storage is already providing organizations with \u201cany data, any format\u201d flexibility. And it\u2019s doing so economically, enabling organizations to retain \u201ccold\u201d data indefinitely \u2013 or at least, for as long as the business requires, and the regulator allows. But reliable and durable object storage will also enable radical architectural simplification at petabyte scale, by, for example, dramatically simplifying high availability and backup and recovery solutions, and operations, and supporting the deployment of \u201cEnterprise Data Operating Systems.\"",
    "Of course, by itself, storing data adds cost, not value - and an Operating System is only one component of a successful computing platform \u2013 so Cloud Analytic Architectures include pluggable processing engines that can read and write directly to the Enterprise Data OS so that data can be processed and value created. In many cases, those processing engines maintain local copies of integrated and modelled data in formats optimized for scalability and performance, rather than for durability and economy. But because the pluggable processing engines also read and write directly to the object storage layer, they enable data to be loaded from the object storage layer, archived to it \u2013 and queried and combined dynamically and at run-time, for example, to support exploration and discovery workloads. With data increasingly being streamed into these data backbones, that means that any application or platform that can plug in to the data operating system is connected to data from across the Enterprise - and in close to real time. That gives organizations an opportunity to modernize decades old data acquisition processes so that analytics can move from being predominantly batch-oriented, to event-driven \u2013 which is a critical concern, as more and more business and business processes are digitized and move online.",
    "So far, so good. But there\u2019s a \u201cbut.\"",
    "If you have a background in large-scale, enterprise data management, look at the reference architectures and design patterns touted by the big Cloud Service Providers (CSPs) and ask yourself \u201cwhat\u2019s wrong with this picture?\u201d There are Services galore, APIs aplenty \u2013 but data products are frequently depicted as little more than an S3-compliant bucket. And that\u2019s leading a generation of architects and designers to make poor decisions that lead to the rapid accumulation of technical debt that ultimately slow the business down, rather than speeding it up. Data that are siloed and hard-wired to just the analytic business process that each pipeline supports necessarily result in the creation of more stovepipes and more silos \u2013 at which point Cloud design patterns can become less \u201cvirtuous circle\u201d and more \u201cvicious cycle.\"",
    "Data and analytics only have real value when they are used by organizations to improve performance, by reducing costs, increasing customer satisfaction or driving new growth. In a time of huge economic uncertainty, what matters are time to value and agility. The best way I know to go faster is to eliminate unnecessary work \u2013 and to automate as much as possible of the rest. Re-using data products is the ultimate \u201celiminate unnecessary work\u201d play \u2013 and it is how successful organizations are able to move rapidly from experimentation and testing to the deployment of predictive analytics in production and at scale.",
    "By themselves, Enterprise Data Operating Systems are necessary rather than sufficient: raw data must be refined and processed into data products before it can be widely exploited to drive improved business results; and integrated and connected data are still required to enable the optimization of end-to-end business processes. Agility and time to value require us to architect and design data products for re-use \u2013 and re-use requires us to think critically about which data products are required to support the analytic use cases that will enable the business, how they will be used and the characteristics that are required.",
    "Many Hadoop-based Data Lakes failed because organizations de-emphasized data management. As data and analytics migrate to the Cloud, organizations that continue to take a laissez-faire approach to data management are likely to fail for a second time with Cloud Object Store based Data Lakes.",
    "What all of that means is that getting your Cloud data architecture right starts with understanding which data products you need to support your analytic processes, the roles that they perform - and the functional and non-functional characteristics that those roles demand. And it means understanding which data will be combined and re-used so frequently that we should incur the cost of centralizing and integrating them \u2013 and which data need merely to be connected, to enables frictionless ETL processing and \u201cwhatever, whenever, wherever\u201d query freedom, so that more users get access to more data, more quickly, wherever that data resides in the ecosystem."
  ],
  "headers": {
    "2": "What matters is what works",
    "6": "Viscous cycle",
    "9": "Getting your Cloud data architecture right"
  },
  "links": {
    "Cloud": "https://www.techradar.com/web-hosting/best-bare-metal-hosting",
    "data": "https://www.techradar.com/best/best-data-visualization-tools",
    "cloud storage": "https://www.techradar.com/news/the-best-cloud-storage",
    "programming": "https://www.techradar.com/news/best-laptop-for-programming",
    "analytics": "https://www.techradar.com/web-hosting/best-bare-metal-hosting"
  }
}